{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nien\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 25s 501us/step - loss: 1.4575 - acc: 0.5409\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.8915 - acc: 0.6896\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.6943 - acc: 0.7570\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.5412 - acc: 0.8101\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.4225 - acc: 0.8538\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.3243 - acc: 0.88532s - loss: 0.3090 - acc: 0.890 - E\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.2561 - acc: 0.9097\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.2113 - acc: 0.92569s - loss: 0.1733 - acc: 0.93 \n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.1751 - acc: 0.9406\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.1639 - acc: 0.9442\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.1397 - acc: 0.9525\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 0.1158 - acc: 0.96080s - loss: 0.1153 - acc: 0.9\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.1144 - acc: 0.9604\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.1230 - acc: 0.9590\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.1010 - acc: 0.96516s - loss: 0.087 - ETA: 5s  - ETA: 1s - loss\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.0740 - acc: 0.9754\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.0820 - acc: 0.9721\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.0996 - acc: 0.9679\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 0.0873 - acc: 0.9715\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.0731 - acc: 0.9769\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.0709 - acc: 0.9761\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0679 - acc: 0.9774\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0607 - acc: 0.9805\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0625 - acc: 0.9797\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0646 - acc: 0.9797\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0619 - acc: 0.9796\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0544 - acc: 0.9816\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0612 - acc: 0.9801\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0533 - acc: 0.9833\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0486 - acc: 0.9840\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0440 - acc: 0.9856\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0572 - acc: 0.9812\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0466 - acc: 0.98490s - loss: 0.0465 - acc: 0.\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0470 - acc: 0.9855\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0360 - acc: 0.98840s - loss: 0.0353 - \n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0532 - acc: 0.9833\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0480 - acc: 0.9855\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0414 - acc: 0.98620s - loss: 0.0413 - acc: 0.\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0410 - acc: 0.9870\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0388 - acc: 0.9878\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0340 - acc: 0.9885\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0308 - acc: 0.9897\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0255 - acc: 0.9914\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0465 - acc: 0.9854\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0383 - acc: 0.9881\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0410 - acc: 0.9870\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.0336 - acc: 0.9890\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0292 - acc: 0.9906\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.0357 - acc: 0.9885\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.0338 - acc: 0.9893 ETA: 0s - loss: 0.0337 - acc: \n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0283 - acc: 0.9905\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0281 - acc: 0.9908\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0327 - acc: 0.9899\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0339 - acc: 0.9891\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0231 - acc: 0.9922\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 0.0253 - acc: 0.99221s - los\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0360 - acc: 0.9891\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0357 - acc: 0.9886\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0213 - acc: 0.9935\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.0221 - acc: 0.99300s - loss: 0.02\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0265 - acc: 0.9918\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.0170 - acc: 0.9944\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0288 - acc: 0.99075s - loss: 0.0204 - - E\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0316 - acc: 0.990311s - loss: 0.0231 - acc: 0.99 - ETA: - ETA: 3s - loss: - ETA: 2s - loss: 0.0 - ETA: 1s - los\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.0209 - acc: 0.9933\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 16s 320us/step - loss: 0.0224 - acc: 0.9928\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0333 - acc: 0.9900\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0226 - acc: 0.9934\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0228 - acc: 0.9928\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.0249 - acc: 0.9922\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 0.0162 - acc: 0.9950\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 16s 322us/step - loss: 0.0230 - acc: 0.9928\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.0196 - acc: 0.99402s - loss: 0.0173 - acc: 0.99 - ETA: 1s - loss: 0.0173 - acc: 0.99 - ETA: 1s - lo - ETA: 0s - loss: 0.0194 - acc: 0\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 16s 316us/step - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0195 - acc: 0.99380s - loss: 0.0194 - acc\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0212 - acc: 0.9936\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0213 - acc: 0.9931\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0190 - acc: 0.9941\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 0.0261 - acc: 0.99221s - l\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0230 - acc: 0.9935\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0175 - acc: 0.9946\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0157 - acc: 0.99494s - loss: 0.0116 - acc: - ETA: 4s - \n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0212 - acc: 0.9934\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 0.0206 - acc: 0.9937\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.0204 - acc: 0.9939\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 16s 320us/step - loss: 0.0159 - acc: 0.9949\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 16s 322us/step - loss: 0.0171 - acc: 0.9949\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 18s 364us/step - loss: 0.0232 - acc: 0.9929\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 0.0269 - acc: 0.9924\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 0.0177 - acc: 0.9950\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.0121 - acc: 0.99630s - loss: 0.0118 - acc\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.0193 - acc: 0.994 - 16s 321us/step - loss: 0.0194 - acc: 0.9940\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 0.0209 - acc: 0.9939\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.0118 - acc: 0.9962\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.0152 - acc: 0.99521s -\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 16s 323us/step - loss: 0.0221 - acc: 0.99321s - loss: 0.0\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 0.0207 - acc: 0.99373s - los - ETA: 1s \n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 16s 320us/step - loss: 0.0135 - acc: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b0568bf080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,(3,3),input_shape=(32,32,3),activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64,(3,3)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(126,activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.63879502e-04, 1.42815395e-08, 1.32336980e-03, 9.97583032e-01,\n",
       "        4.16756870e-04, 2.30176234e-09, 7.01413754e-08, 2.99209364e-06,\n",
       "        9.87039311e-06, 3.22275522e-16]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
